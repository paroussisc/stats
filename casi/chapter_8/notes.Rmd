---
title: "Chapter 8"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## GLMs and Regression Trees

- GLMs extend ordinary linear regression (least squares) to responses from any exponential family (gamma, Poisson, binomial etc.)
- All the information from a $p$-parameter GLM is summarised in a $p$-parameter vector, making it still interpretable for large $N$
- GLMs minimise the total deviance betweem the data and the params, analagous to least squares
- Regression trees can be used - they are totally non-parametric, which is useful with bigger, less structured datasets that we tend to work with lately. They are much more useful predictively when using bootstrap aggregation (Random Forests).


